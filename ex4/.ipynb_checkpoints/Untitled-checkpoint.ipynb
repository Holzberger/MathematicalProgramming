{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The lagrangian dual of the problem is:\n",
    "\\begin{gather}\n",
    "X:=\\{(x,y)\\in \\mathbb{R}_+^{N+M}\\times \\mathbb{B}^{N}: \\sum\\limits_{j\\in N} x_{i,j}=1 \\}\\\\\n",
    "\\max\\limits_{(x,y)\\in X} \\sum\\limits_{i \\in M} \\sum\\limits_{j \\in N} p_{i,j}x_{i,j} + \n",
    "\\sum\\limits_{i \\in M} \\sum\\limits_{j \\in N} u_{i,j}(y_j-x_{i,j})- \\sum\\limits_{j \\in N} f_j y_j\n",
    "\\end{gather}\n",
    "We aim to show by Theorem 4 that $w_{LD}$ is the same as the best bound of the LP-relaxation. Therefore define :\n",
    "\\begin{gather}\n",
    "\\hat{X}:=\\{(x,y)\\in \\mathbb{R}_+^{N+M}\\times [0,1]^{N}: \\sum\\limits_{j\\in N} x_{i,j}=1 \\}\n",
    "\\end{gather}\n",
    "Next take arbitrary $\\hat{z}_1,\\hat{z}_2\\in \\hat{X}$, let $\\lambda\\in[0,1]$ and defne the convex combination $\\hat{z}_3:= \\lambda\\hat{z}_1 + (1-\\lambda)\\hat{z}_2$. Then for $\\hat{z}_3$ we have: $\\sum\\limits_{j\\in N} \\hat{x}_{3,i,j} = \\sum\\limits_{j\\in N}\\lambda \\hat{x}_{1,i,j} + \\sum\\limits_{j\\in N} (1-\\lambda)\\hat{x}_{2,i,j}=\\lambda+(1-\\lambda)$ and further $0 \\leq\\hat{y}_{3,j} = \\lambda \\hat{y}_{1,j} + (1-\\lambda) \\hat{y}_{2,j}\\leq \\lambda +(1-\\lambda)=1\\quad \\forall j\\in N$, which shows $conv(X)=\\hat{X}$ such that Theorem 4 is applicable. In general we have by Theorem 3 and Theorem 4 that the bound $w_{LD}$ is at least as good as the best bound of the LP-relaxation. Therefore $w_{LD}$ can get weaker and it not always equals the best LP-relaxation bound."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To solve the LD we can rewrite the problem as:\n",
    "\\begin{gather}\n",
    "X:=\\{(x,y)\\in \\mathbb{R}_+^{N+M}\\times \\mathbb{B}^{N}: \\sum\\limits_{j\\in N} x_{i,j}=1 \\}\\\\\n",
    "\\max\\limits_{(x,y)\\in X} \\sum\\limits_{i \\in M} \\sum\\limits_{j \\in N} (p_{i,j} -u_{i,j})x_{i,j} +\n",
    "\\sum\\limits_{j \\in N} y_j(-f_j + \\sum\\limits_{i\\in M}u_{i,j})\n",
    "\\end{gather}\n",
    "\n",
    "Step1: calculate the matrix $a_{i,j}=p_{i,j}-u_{i,j}$ and find for all $i$ the maximum argument $j_{max}(i)=argmax_{j} a_{i,j}$. Then if $a_{i,j_{max}(i)}>0$ set $x_{i,j_{max}(i)}=1$ and $x_{i,j_{max}(i)}=0$ else. This step can be done in $\\mathcal{O}(NM)$.\n",
    "\n",
    "Step2: calculate $\\sum\\limits_{i\\in M}u_{i,j} = \\hat{u}_j \\quad j\\in N$. If $\\hat{u}_j-f_j>0$ let $y_j=1$, else set $y_j=0$. Step2 can be done in $\\mathcal{O}(NM)$.\n",
    "\n",
    "Therefore the overall complexity is $\\mathcal{O}(NM)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
